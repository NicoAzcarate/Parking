{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Correcci√≥n de Data Leakage: Divisi√≥n Cronol√≥gica\n",
                "\n",
                "## El Problema: Data Leakage Temporal\n",
                "En el notebook anterior (`03_ML.ipynb`), utilizamos `train_test_split` con `shuffle=True` (aleatorio). \n",
                "Dado que nuestras im√°genes provienen de una **secuencia de video** (time-series), las im√°genes consecutivas son casi id√©nticas.\n",
                "\n",
                "Al mezclar aleatoriamente:\n",
                "- El modelo ve el **mismo coche** en el instante $t$ (Entrenamiento) y en el instante $t+1$ (Test).\n",
                "- El modelo no aprende a distinguir \"textura de coche\" vs \"textura de asfalto\", sino que **memoriza** los coches est√°ticos espec√≠ficos de esa grabaci√≥n.\n",
                "- Resultado: m√©tricas artificialmente perfectas (F1-Score 1.0) pero fallos en el mundo real.\n",
                "\n",
                "## La Soluci√≥n: Divisi√≥n Cronol√≥gica (Chronological Split)\n",
                "Para evaluar realmente si el modelo generaliza:\n",
                "1. Ordenamos las im√°genes por **tiempo** (nombre de archivo).\n",
                "2. Usamos el primer **80%** para **Entrenar**.\n",
                "3. Usamos el √∫ltimo **20%** futuro para **Test**.\n",
                "\n",
                "Esto obliga al modelo a predecir sobre coches e iluminaci√≥n que **nunca ha visto antes**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import pickle\n",
                "import json\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import confusion_matrix, classification_report\n",
                "\n",
                "# Configuraci√≥n\n",
                "DATA_DIR = Path(\"data\")\n",
                "GT_FILE = \"ground_truth.json\"\n",
                "PLAZAS_FILE = \"plazas.pickle\"\n",
                "MODEL_FILE = \"model_corrected.pkl\"  # Guardaremos un nuevo modelo corregido"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Carga de Datos y Ordenamiento Cronol√≥gico\n",
                "Es cr√≠tico ordenar las claves del JSON para asegurar la secuencia temporal."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üìä Total Im√°genes: 8\n",
                        "   ‚úÖ Train (Pasado): 6 im√°genes\n",
                        "   üß™ Test (Futuro):  2 im√°genes\n"
                    ]
                }
            ],
            "source": [
                "def cargar_datos_cronologicos():\n",
                "    if not Path(PLAZAS_FILE).exists() or not Path(GT_FILE).exists():\n",
                "        raise FileNotFoundError(\"Faltan archivos de datos (plazas.pickle o ground_truth.json)\")\n",
                "        \n",
                "    with open(PLAZAS_FILE, 'rb') as f: plazas = pickle.load(f)\n",
                "    with open(GT_FILE, 'r') as f: ground_truth = json.load(f)\n",
                "    \n",
                "    # ORDENAR CRONOL√ìGICAMENTE\n",
                "    # Los nombres de archivo tienen formato YYYY-MM-DD_HH_MM_SS, por lo que sort() funciona directo\n",
                "    sorted_img_names = sorted(ground_truth.keys())\n",
                "    \n",
                "    return plazas, ground_truth, sorted_img_names\n",
                "\n",
                "plazas, ground_truth, sorted_images = cargar_datos_cronologicos()\n",
                "\n",
                "# Divisi√≥n 80/20 Estricta\n",
                "split_idx = int(len(sorted_images) * 0.8)\n",
                "train_imgs = sorted_images[:split_idx]\n",
                "test_imgs = sorted_images[split_idx:]\n",
                "\n",
                "print(f\"üìä Total Im√°genes: {len(sorted_images)}\")\n",
                "print(f\"   ‚úÖ Train (Pasado): {len(train_imgs)} im√°genes\")\n",
                "print(f\"   üß™ Test (Futuro):  {len(test_imgs)} im√°genes\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Procesamiento e Ingenier√≠a de Caracter√≠sticas\n",
                "Usamos el mismo pipeline que antes, pero construyendo los arrays X/y secuencialmente."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚è≥ Construyendo Train Set...\n",
                        "‚è≥ Construyendo Test Set...\n",
                        "\n",
                        "üì¶ Dataset Final:\n",
                        "   Train: 306 muestras\n",
                        "   Test:  102 muestras\n"
                    ]
                }
            ],
            "source": [
                "def preprocess_image(image):\n",
                "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
                "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
                "    gray = clahe.apply(gray)\n",
                "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
                "    return blur\n",
                "\n",
                "def extract_features(roi_gray, roi_binary, roi_color):\n",
                "    pixels = cv2.countNonZero(roi_binary)\n",
                "    match_mean, match_std = cv2.meanStdDev(roi_gray)\n",
                "    texture = match_std[0][0]\n",
                "    hsv = cv2.cvtColor(roi_color, cv2.COLOR_BGR2HSV)\n",
                "    s_mean, s_std = cv2.meanStdDev(hsv[:,:,1])\n",
                "    saturation = s_mean[0][0]\n",
                "    return [pixels, texture, saturation]\n",
                "\n",
                "def build_dataset(image_list, gt_data, plazas_rects):\n",
                "    X, y = [], []\n",
                "    for img_name in image_list:\n",
                "        path = DATA_DIR / img_name\n",
                "        if not path.exists(): continue\n",
                "        \n",
                "        image = cv2.imread(str(path))\n",
                "        processed = preprocess_image(image)\n",
                "        \n",
                "        # Binarizaci√≥n adaptativa\n",
                "        binary = cv2.adaptiveThreshold(processed, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
                "                                     cv2.THRESH_BINARY_INV, 25, 15)\n",
                "        binary = cv2.medianBlur(binary, 5)\n",
                "        \n",
                "        labels = gt_data[img_name]\n",
                "        \n",
                "        for idx, rect in enumerate(plazas_rects):\n",
                "            if idx >= len(labels): break\n",
                "            x, py, w, h = rect\n",
                "            \n",
                "            roi_gray = processed[py:py+h, x:x+w]\n",
                "            roi_binary = binary[py:py+h, x:x+w]\n",
                "            roi_color = image[py:py+h, x:x+w]\n",
                "            \n",
                "            feat = extract_features(roi_gray, roi_binary, roi_color)\n",
                "            X.append(feat)\n",
                "            y.append(labels[idx])\n",
                "            \n",
                "    return np.array(X), np.array(y)\n",
                "\n",
                "print(\"‚è≥ Construyendo Train Set...\")\n",
                "X_train, y_train = build_dataset(train_imgs, ground_truth, plazas)\n",
                "\n",
                "print(\"‚è≥ Construyendo Test Set...\")\n",
                "X_test, y_test = build_dataset(test_imgs, ground_truth, plazas)\n",
                "\n",
                "print(f\"\\nüì¶ Dataset Final:\")\n",
                "print(f\"   Train: {X_train.shape[0]} muestras\")\n",
                "print(f\"   Test:  {X_test.shape[0]} muestras\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Entrenamiento y Validaci√≥n Realista"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üß† Entrenando SVM con kernel RBF...\n",
                        "\n",
                        "üìä Resultados REALISTAS (Test Set):\n",
                        "----------------------------------------\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "       Libre       1.00      0.91      0.95        22\n",
                        "     Ocupado       0.98      1.00      0.99        80\n",
                        "\n",
                        "    accuracy                           0.98       102\n",
                        "   macro avg       0.99      0.95      0.97       102\n",
                        "weighted avg       0.98      0.98      0.98       102\n",
                        "\n",
                        "\n",
                        "Matriz de Confusi√≥n:\n",
                        "TN (Libres OK):    20\n",
                        "FP (Falsos Ocup):  2\n",
                        "FN (Falsos Libres):0\n",
                        "TP (Ocupados OK):  80\n"
                    ]
                }
            ],
            "source": [
                "print(\"üß† Entrenando SVM con kernel RBF...\")\n",
                "model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "# Predicci√≥n en datos futuros (Test)\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "print(\"\\nüìä Resultados REALISTAS (Test Set):\")\n",
                "print(\"-\"*40)\n",
                "print(classification_report(y_test, y_pred, target_names=['Libre', 'Ocupado']))\n",
                "\n",
                "print(\"\\nMatriz de Confusi√≥n:\")\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "print(f\"TN (Libres OK):    {cm[0][0]}\")\n",
                "print(f\"FP (Falsos Ocup):  {cm[0][1]}\")\n",
                "print(f\"FN (Falsos Libres):{cm[1][0]}\")\n",
                "print(f\"TP (Ocupados OK):  {cm[1][1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Conclusi√≥n\n",
                "Estas m√©tricas reflejan el comportamiento real del modelo ante nuevos frames de video. El F1-Score ha bajado ligeramente respecto al 1.0 perfecto del enfoque aleatorio, ahora es una m√©trica honesta."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
